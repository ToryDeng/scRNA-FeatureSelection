{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.neighbors import NearestCentroid, NearestNeighbors\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import rpy2.robjects as robjects\n",
    "from scipy.optimize import linprog\n",
    "# LightGBM\n",
    "from lightgbm import LGBMClassifier\n",
    "# xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from loess.loess_1d import loess_1d\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_name, with_marker=False, norm=False, scale_factor=1e4):\n",
    "    \"\"\"\n",
    "    description:\n",
    "    for specific data_name, get the corresponding data.\n",
    "    \n",
    "    parameters:\n",
    "    data_name: the dataset you want to get\n",
    "    with_marker: whether to return marker genes\n",
    "    norm: whether to normalize features(using the normalization in Seurat)\n",
    "    scale_factor: size factor, default 1e4\n",
    "    \n",
    "    return:\n",
    "    if with_marker=False, features(row:cell, col:gene, dataframe) and labels(dataframe) of raw data\n",
    "    if with_marker=True, features(row:cell, col:gene, dataframe), labels(dataframe) and marker genes(array) of raw data\n",
    "    \"\"\"\n",
    "    if data_name[:4] == 'PBMC':\n",
    "        os.chdir('/home/tdeng/SingleCell/data/PBMC/integrated data')\n",
    "        if data_name == 'PBMC':\n",
    "            data = pd.read_hdf('PBMC_AllCells_withLables.h5', key='AllCells')\n",
    "            features, labels = data.iloc[:, :-1], data.iloc[:,-1]\n",
    "        elif 0 < int(data_name[4:]) < 100:\n",
    "            features = pd.read_csv('raw_features_sample' + data_name[4:] + '.csv', index_col=0)\n",
    "            labels = pd.read_csv('raw_labels_sample' + data_name[4:] + '.csv', usecols=[1])\n",
    "        else:\n",
    "            print(\"parameter 'data_name' is wrong!\")\n",
    "            return None\n",
    "        \n",
    "        if norm:\n",
    "            features = np.log1p(features / features.sum(1).values.reshape(features.shape[0], 1) * scale_factor)\n",
    "        if with_marker:\n",
    "            part1 = np.squeeze(pd.read_csv('/home/tdeng/SingleCell/data/PBMC/hsPBMC_markers_10x.txt', usecols=[0]).values)\n",
    "            part2 = np.squeeze(pd.read_csv('/home/tdeng/SingleCell/data/PBMC/blood_norm_marker.txt', usecols=[1]).values)\n",
    "            markers = np.union1d(part1, part2)\n",
    "            return features, labels, markers\n",
    "        return features, labels\n",
    "    elif data_name in ['muraro', 'segerstolpe', 'xin']:\n",
    "        os.chdir('/home/tdeng/SingleCell/data/pancreas/separated data')\n",
    "        features = pd.read_csv(data_name.capitalize() + '_pancreas_filtered.csv', index_col=0)\n",
    "        labels = pd.read_csv(data_name.capitalize() + '_trueID_filtered.csv', usecols=[1])\n",
    "        if norm:\n",
    "            features = np.log1p(features / features.sum(1).values.reshape(features.shape[0], 1) * scale_factor)\n",
    "        if with_marker:\n",
    "            markers = np.squeeze(pd.read_csv('/home/tdeng/SingleCell/data/pancreas/pancreasMarkerGenes.csv',\n",
    "                                             usecols=[0]).values)\n",
    "            return features, labels, markers\n",
    "        return features, labels\n",
    "    elif data_name == 'all_pancreas':\n",
    "        os.chdir('/home/tdeng/SingleCell/data/pancreas/integrated data')\n",
    "        features = pd.read_csv('features.csv', index_col=0)\n",
    "        labels = pd.read_csv('labels.csv', usecols=[1])\n",
    "        if norm:\n",
    "            features = np.log1p(features / features.sum(1).values.reshape(features.shape[0], 1) * scale_factor)\n",
    "        if with_marker:\n",
    "            markers = np.squeeze(pd.read_csv('/home/tdeng/SingleCell/data/pancreas/pancreasMarkerGenes.csv',\n",
    "                                             usecols=[0]).values)\n",
    "            return features, labels, markers\n",
    "        return features, labels\n",
    "    else:\n",
    "        print(\"parameter 'data_name' is wrong!\")\n",
    "        return None\n",
    "    \n",
    "    \n",
    "def get_gene_names(columns):\n",
    "    \"\"\"\n",
    "    description:\n",
    "    get gene names array from features(dataframe).\n",
    "    \n",
    "    parameter:\n",
    "    columns:dataframe.columns\n",
    "    \n",
    "    return:\n",
    "    an array contains gene names\n",
    "    \"\"\"\n",
    "    if '__' in columns[0]:\n",
    "        gene_names = pd.Series(columns).str.split('__',expand=True).iloc[:,0].values\n",
    "    elif '\\t' in columns[0]:\n",
    "        gene_names = pd.Series(columns).str.split('\\t', expand=True).iloc[:,1].values\n",
    "    else:\n",
    "        gene_names = pd.Series(columns).values\n",
    "    return gene_names\n",
    "\n",
    "def save_filtered_genes(X, all_genes, selected_genes):\n",
    "    os.chdir(r'/home/tdeng/SingleCell/FeatureSelection/R/temp filtered data')\n",
    "    mask = np.isin(all_genes, selected_genes)\n",
    "    X.loc[:, mask].to_csv('temp_X.csv')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_centroid_select(X, y, shrink_threshold):\n",
    "    n_samples, n_features = X.shape\n",
    "    le = LabelEncoder()\n",
    "    y_ind = le.fit_transform(y)\n",
    "    classes = le.classes_\n",
    "    n_classes = classes.size\n",
    "    centroids_ = np.empty((n_classes, n_features), dtype=np.float64)\n",
    "    nk = np.zeros(n_classes)\n",
    "    for cur_class in range(n_classes):\n",
    "        center_mask = y_ind == cur_class\n",
    "        nk[cur_class] = np.sum(center_mask)\n",
    "    if n_classes < 2:\n",
    "        raise ValueError('The number of classes has to be greater than'\n",
    "                             ' one; got %d class' % (n_classes))\n",
    "    if shrink_threshold is not None:\n",
    "        if np.all(np.ptp(X, axis=0) == 0):\n",
    "            raise ValueError(\"All features have zero variance. \"\n",
    "                                    \"Division by zero.\")\n",
    "        dataset_centroid_ = np.mean(X, axis=0)\n",
    "\n",
    "        # m parameter for determining deviation\n",
    "        m = np.sqrt((1. / nk) - (1. / n_samples))\n",
    "        # Calculate deviation using the standard deviation of centroids.\n",
    "        variance = (X - centroids_[y_ind]) ** 2\n",
    "        variance = variance.sum(axis=0)\n",
    "        s = np.sqrt(variance / (n_samples - n_classes))\n",
    "        s += np.median(s)  # To deter outliers from affecting the results.\n",
    "        mm = m.reshape(len(m), 1)  # Reshape to allow broadcasting.\n",
    "        ms = mm * s\n",
    "        deviation = ((centroids_ - dataset_centroid_) / ms)\n",
    "        # Soft thresholding: if the deviation crosses 0 during shrinking,\n",
    "        # it becomes zero.\n",
    "        signs = np.sign(deviation)\n",
    "        deviation = (np.abs(deviation) - shrink_threshold)\n",
    "        np.clip(deviation, 0, None, out=deviation)\n",
    "        deviation *= signs\n",
    "        return np.var(deviation, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_constraints(data, labels, k):\n",
    "    \"\"\"\n",
    "    :param data: a N × d array (d dimension, N number of points)\n",
    "    :param labels: a N × 1 array with labels from 1 to L\n",
    "    :param k: the number of neighbors to select\n",
    "    :return:\n",
    "    Delta: a d × n array, where each column is of the form (v-w).^2 where v and w are nearest neighbors with different labels\n",
    "    smallest: the smallest norm of vectors in Delta\n",
    "    \"\"\"\n",
    "    n_total, d = data.shape\n",
    "    smallest = np.inf\n",
    "    classes = np.unique(labels)\n",
    "    seperated = [data[np.where(labels == cell_class)] for cell_class in classes]  # 0, 1,..., L\n",
    "    idx = 0\n",
    "\n",
    "    Delta = np.zeros(shape=(k * n_total, d))\n",
    "    for c in range(len(seperated)):\n",
    "        seperated_copy = seperated.copy()\n",
    "        del seperated_copy[c]\n",
    "        current_class = seperated[c]\n",
    "        other_classes = np.concatenate(seperated_copy)\n",
    "        distances, indices = NearestNeighbors(n_neighbors=k, metric='euclidean').fit(other_classes).kneighbors(\n",
    "            current_class)\n",
    "        if smallest > distances.min():\n",
    "            smallest = distances.min()\n",
    "        for i in range(indices.shape[0]):\n",
    "            for j in range(indices.shape[1]):\n",
    "                nn_idx = indices[i, j]\n",
    "                delta = current_class[i, :] - other_classes[nn_idx, :]\n",
    "                Delta[idx, :] = delta\n",
    "                idx += 1\n",
    "    Delta, smallest = Delta * Delta, smallest * smallest\n",
    "    return Delta.T, smallest\n",
    "\n",
    "\n",
    "def sqz_hinge(Delta, epsilon, dim_target, lam=None):\n",
    "    \"\"\"\n",
    "    :param Delta: a d x N array of constraints, d is the dimension of the space and N is the number of constraints\n",
    "    :param epsilon: a hinge parameter\n",
    "    :param dim_target: number of markers to select\n",
    "    :param lam: a N x d array stating a penalization for each constraint\n",
    "    (typically all ones or inversely proportional to the number of on the number of points in the cluster)\n",
    "    :return: M: a dim x 1 binary array. M(t)=1 implies that t is a selected marker\n",
    "    \"\"\"\n",
    "    d, N = Delta.shape\n",
    "    f = np.concatenate([np.zeros(shape=(d,)), np.ones(shape=(N,))])\n",
    "\n",
    "    if lam is None:\n",
    "        b = -epsilon * np.ones(shape=(N,))\n",
    "    else:\n",
    "        b = -epsilon * np.ones(shape=(N,)) / lam\n",
    "    b = np.concatenate([b, np.ones((1,)) * dim_target], axis=0)\n",
    "\n",
    "    A = np.concatenate([-Delta.T, -np.identity(N)], axis=1)\n",
    "    bottom = np.concatenate([np.ones(shape=(1, d)), np.zeros(shape=(1, N))], axis=1)\n",
    "    A = np.concatenate([A, bottom], axis=0)\n",
    "\n",
    "    lb = np.zeros(shape=(d + N,))\n",
    "    ub = np.concatenate([np.ones((d,)), np.inf*np.ones((N,))])\n",
    "    bounds = [(left, right) for left, right in zip(lb, ub)]\n",
    "\n",
    "    res = linprog(c=f, A_ub=A, b_ub=b, bounds=bounds, options={'tol': 1e-4})\n",
    "    M = res['x'][:d]  # numpy.ndarray, just select all genes\n",
    "    return M\n",
    "\n",
    "\n",
    "def scGeneFit(data, labels, num_markers, opt=None):\n",
    "    constraints_neighbors = 4\n",
    "    hinge_scale = 0.1\n",
    "\n",
    "    D, s = select_constraints(data=data, labels=labels, k=constraints_neighbors)\n",
    "    M = sqz_hinge(Delta=D, epsilon=hinge_scale*s, dim_target=num_markers)\n",
    "    return M  # feature importance? hierarchy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def select_features_from_importances(importances, feature_num, all_features):\n",
    "    if importances.shape[0] != all_features.shape[0]:\n",
    "        print('The length of importances and gene names are not the same! Please check again!')\n",
    "        return None\n",
    "    else:\n",
    "        selected_features = []\n",
    "        indices=np.argsort(importances)[::-1]\n",
    "        for f in range(feature_num):\n",
    "            #print (\"%2d) %-*s %f\" % (f+1,30,gene_name[f],importances[indices[f]]) )\n",
    "            selected_features.append(all_features[indices[f]])\n",
    "        return np.array(selected_features)\n",
    "\n",
    "\n",
    "def evaluate_method(trusted_features, selected_features, rank=True):\n",
    "    \"\"\"\n",
    "    description:\n",
    "    calculate 2 metrics: num of marker genes found and MRR(Mean Reciprocal Rank).\n",
    "    \"\"\"\n",
    "    if rank:\n",
    "        rank = np.argwhere(np.isin(selected_features, trusted_features))\n",
    "        print('MRR:{:.5f}'.format(np.sum(1 / (rank + 1)) / rank.shape[0]))\n",
    "    print('marker genes found:{}\\n'.format(np.intersect1d(trusted_features, selected_features).shape[0]))\n",
    "    \n",
    "    \n",
    "\n",
    "def find_not_const_index(X):\n",
    "    \"\"\"\n",
    "    description:\n",
    "    find indexes of genes which have const values.\n",
    "    \n",
    "    return:\n",
    "    indexs of genes\n",
    "    \"\"\"\n",
    "    mean = X.mean(axis=0)\n",
    "    return np.where(mean != 0)\n",
    "\n",
    "#calculate feature importances\n",
    "def select_features_from_data(data_name, feature_num, method, all_features, X_train, y_train):\n",
    "    \"\"\"\n",
    "    description:\n",
    "    calculate the importances of features and call 'select_features_from_importances' function to get selected features.\n",
    "    \n",
    "    parameter:\n",
    "    feature_num:the number of features you want to obtain\n",
    "    method:the method you want to use\n",
    "    all_features: feature names from which you select the most important ones\n",
    "    X_train:expression matrix(row:cell,col:gene)\n",
    "    y_train:labels\n",
    "    \n",
    "    return:\n",
    "    an array contains selected genes\n",
    "    \"\"\"\n",
    "    print('the method you are using is {}.'.format(method))\n",
    "    if method == 'rf':  #random forest\n",
    "        forest=RandomForestClassifier(n_estimators=100,n_jobs=15,random_state=0, verbose=0).fit(X_train,y_train)\n",
    "        importances=forest.feature_importances_\n",
    "        result = select_features_from_importances(importances, feature_num, all_features)\n",
    "        return result\n",
    "    elif method == 'lgb':\n",
    "        lgb = LGBMClassifier(n_jobs=15, random_state=0).fit(X_train, y_train)\n",
    "        importances = lgb.feature_importances_\n",
    "        result = select_features_from_importances(importances, feature_num, all_features)\n",
    "        return result\n",
    "    elif method == 'xgb':\n",
    "        le = LabelEncoder()\n",
    "        y_train = le.fit_transform(y_train)\n",
    "        xgb = XGBClassifier(eval_metric='mlogloss', use_label_encoder=False, nthread=15).fit(X_train, y_train)\n",
    "        importances = xgb.feature_importances_\n",
    "        result = select_features_from_importances(importances, feature_num, all_features)\n",
    "        return result\n",
    "    elif method == 'seurat':\n",
    "        not_const = find_not_const_index(X_train)   #(samples_mean != 0) is the same as (samples_var != 0))\n",
    "        not_const_mean, not_const_var, not_const_gene = np.squeeze(X_train[:,not_const].mean(axis=0)), np.squeeze(X_train[:,not_const].var(axis=0)), all_features[not_const]\n",
    "        mean_fit, var_fit, weigts = loess_1d(np.log10(not_const_mean), np.log10(not_const_var), frac=0.3, degree=2)\n",
    "\n",
    "        z = (X_train[:,not_const] - not_const_mean) / (10 ** (var_fit / 2))\n",
    "        z[z > X_train.shape[0] ** 0.5] = X_train.shape[0] ** 0.5\n",
    "        z = np.var(np.squeeze(z), axis=0)\n",
    "        \n",
    "        result = select_features_from_importances(z, feature_num, not_const_gene)\n",
    "        return result\n",
    "    elif method == 'var':\n",
    "        var = np.var(X_train, axis=0)\n",
    "        result = select_features_from_importances(var, feature_num, all_features)\n",
    "        return result\n",
    "    elif method == 'cv2':\n",
    "        not_const = find_not_const_index(X_train)\n",
    "        print(not_const)\n",
    "        not_const_X, not_const_gene = np.squeeze(X_train[:,not_const]), all_features[not_const]\n",
    "        cv = np.squeeze(np.std(not_const_X, axis=0) / np.squeeze(np.mean(not_const_X, axis=0)))\n",
    "        print('num of genes whose mean values are less than 1e-4:{}'.format(np.sum(np.squeeze(np.mean(not_const_X, axis=0)) < 1e-4)))\n",
    "        result = select_features_from_importances(cv ** 2, feature_num, not_const_gene)\n",
    "        return result\n",
    "    elif method == 'nsc':\n",
    "        not_const = find_not_const_index(X_train)\n",
    "        not_const_X, not_const_gene = np.squeeze(X_train[:,not_const]), all_features[not_const]\n",
    "        th_dict = {'shrink_threshold':np.arange(0.0, 1.01, 0.01)}\n",
    "        gs = GridSearchCV(estimator=NearestCentroid(), param_grid=th_dict, cv=3, scoring='balanced_accuracy').fit(not_const_X, y_train)\n",
    "        print('best score:{}, best threshold:{}'.format(gs.best_score_, gs.best_params_['shrink_threshold']))\n",
    "        \n",
    "        var = nearest_centroid_select(not_const_X, y_train, shrink_threshold=gs.best_params_['shrink_threshold'])\n",
    "        result = select_features_from_importances(var, feature_num, not_const_gene)\n",
    "        return result\n",
    "    elif method == 'm3drop':\n",
    "        os.chdir('/home/tdeng/R/M3Drop/')\n",
    "        genes = pd.read_csv(data_name + '_markers.csv', usecols=[1, 3])\n",
    "        genes.sort_values(by='p.value', inplace=True, ascending=True)\n",
    "        return get_gene_names(genes['Gene'].values[:feature_num])# '\\t' --> '.'\n",
    "    elif method == 'cellassign':\n",
    "        os.chdir('/home/tdeng/R/CellAssign/')\n",
    "        genes = np.squeeze(pd.read_csv(data_name + '_markers.csv', usecols=[0]).values)\n",
    "        return get_gene_names(genes)\n",
    "    elif method == 'deviance':\n",
    "        os.chdir('/home/tdeng/R/Deviance/')\n",
    "        genes = np.squeeze(pd.read_csv(data_name + '_markers.csv', usecols=[0]).values)\n",
    "        return get_gene_names(genes)\n",
    "    elif method == 'scGeneFit':\n",
    "        not_const = find_not_const_index(X_train)\n",
    "        not_const_X, not_const_gene = np.squeeze(X_train[:,not_const]), all_features[not_const]\n",
    "        print(\"removing {} genes\".format(X_train.shape[1] - not_const_X.shape[1]))\n",
    "        le = LabelEncoder()\n",
    "        y_encoded = le.fit_transform(y_train)\n",
    "        importances = scGeneFit(not_const_X, y_encoded, 0)\n",
    "        result = select_features_from_importances(importances, feature_num, not_const_gene)\n",
    "        return result\n",
    "    else: \n",
    "        print(\"the parameter 'method' is wrong!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(n_features):\n",
    "    \"\"\"\n",
    "    select genes from datasets using specific methods(not split dataset).\n",
    "    \"\"\"\n",
    "    for dataset in ['muraro','segerstolpe', 'xin', 'all_pancreas']:#\n",
    "        print('***************{}***************'.format(dataset))\n",
    "        \n",
    "        # using methods on normalized data\n",
    "        X, y, trusted_markers = get_data(dataset, with_marker=True, norm=True)\n",
    "        gene_names = get_gene_names(X.columns)\n",
    "        for method in ['rf', 'scGeneFit']:#,, 'lgb', 'xgb', 'var', 'cv2' 'nsc'\n",
    "            result = select_features_from_data(dataset, n_features, method, all_features=gene_names, X_train=X.values, y_train=np.squeeze(y.values))\n",
    "            evaluate_method(trusted_markers, result)\n",
    "            save_filtered_genes(X, y, gene_names, result)\n",
    "        \n",
    "        # using methods on raw data\n",
    "#         X, y, trusted_markers = get_data(dataset, with_marker=True, norm=False)\n",
    "#         gene_names = get_gene_names(X.columns)\n",
    "#         for method in ['scGeneFit']:\n",
    "#             result = select_features_from_data(dataset, n_features, method, all_features=gene_names, X_train=X.values, y_train=np.squeeze(y.values))\n",
    "#             evaluate_method(trusted_markers, result)\n",
    "        \n",
    "        # evaluate results in R folder\n",
    "#         for method in ['m3drop', 'cellassign', 'deviance']:\n",
    "#             result = select_features_from_data(dataset, n_features, method, all_features=gene_names, X_train=X.values, y_train=np.squeeze(y.values))\n",
    "#             evaluate_method(trusted_markers, result, rank=True)  # actually, X_train and y_train are not used.\n",
    "        \n",
    "        # show information about marker genes\n",
    "        print('All marker genes:{}. In data:{}.'.format(trusted_markers.shape[0], np.intersect1d(gene_names, trusted_markers).shape[0]))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************muraro***************\n",
      "the method you are using is rf.\n",
      "MRR:0.02883\n",
      "marker genes found:125\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Item wrong length 19127 instead of 2122.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-86547e848d55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mselect_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-1477debb4d3e>\u001b[0m in \u001b[0;36mselect_features\u001b[0;34m(n_features)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_features_from_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgene_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mevaluate_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrusted_markers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0my_filtered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_filtered_genes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgene_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_filtered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-6c4f4b17f86f>\u001b[0m in \u001b[0;36msave_filtered_genes\u001b[0;34m(X, y, all_genes, selected_genes)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_genes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_genes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'temp_X.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2895\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2942\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m             raise ValueError(\n\u001b[0;32m-> 2944\u001b[0;31m                 \u001b[0;34mf\"Item wrong length {len(key)} instead of {len(self.index)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2945\u001b[0m             )\n\u001b[1;32m   2946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Item wrong length 19127 instead of 2122."
     ]
    }
   ],
   "source": [
    "select_features(n_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: SingleCellExperiment\n",
      "\n",
      "R[write to console]: Loading required package: SummarizedExperiment\n",
      "\n",
      "R[write to console]: Loading required package: GenomicRanges\n",
      "\n",
      "R[write to console]: Loading required package: stats4\n",
      "\n",
      "R[write to console]: Loading required package: BiocGenerics\n",
      "\n",
      "R[write to console]: Loading required package: parallel\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: ‘BiocGenerics’\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:parallel’:\n",
      "\n",
      "    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,\n",
      "    clusterExport, clusterMap, parApply, parCapply, parLapply,\n",
      "    parLapplyLB, parRapply, parSapply, parSapplyLB\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    IQR, mad, sd, var, xtabs\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:base’:\n",
      "\n",
      "    anyDuplicated, append, as.data.frame, basename, cbind, colnames,\n",
      "    dirname, do.call, duplicated, eval, evalq, Filter, Find, get, grep,\n",
      "    grepl, intersect, is.unsorted, lapply, Map, mapply, match, mget,\n",
      "    order, paste, pmax, pmax.int, pmin, pmin.int, Position, rank,\n",
      "    rbind, Reduce, rownames, sapply, setdiff, sort, table, tapply,\n",
      "    union, unique, unsplit, which, which.max, which.min\n",
      "\n",
      "\n",
      "R[write to console]: Loading required package: S4Vectors\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: ‘S4Vectors’\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from ‘package:base’:\n",
      "\n",
      "    expand.grid\n",
      "\n",
      "\n",
      "R[write to console]: Loading required package: IRanges\n",
      "\n",
      "R[write to console]: Loading required package: GenomeInfoDb\n",
      "\n",
      "R[write to console]: Error: package or namespace load failed for ‘GenomeInfoDb’ in dyn.load(file, DLLpath = DLLpath, ...):\n",
      " unable to load shared object '/usr/lib64/R/library/RCurl/libs/RCurl.so':\n",
      "  /usr/lib64/R/library/RCurl/libs/RCurl.so: undefined symbol: R_ClassSymbol\n",
      "\n",
      "R[write to console]: Failed with error:  \n",
      "R[write to console]: \n",
      "R[write to console]: ‘package ‘GenomeInfoDb’ could not be loaded’\n",
      "R[write to console]: \n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: Loading required package: Hmisc\n",
      "\n",
      "R[write to console]: Loading required package: lattice\n",
      "\n",
      "R[write to console]: Loading required package: survival\n",
      "\n",
      "R[write to console]: Loading required package: Formula\n",
      "\n",
      "R[write to console]: Loading required package: ggplot2\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: ‘Hmisc’\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:base’:\n",
      "\n",
      "    format.pval, units\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "robjects.r.source('/home/tdeng/SingleCell/FeatureSelection/R/R code/clustering methods/main.R')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
